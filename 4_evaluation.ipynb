{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKhCfNnv_Y9V"
      },
      "source": [
        "## Evaluating Finetuned Model\n",
        "\n",
        "In this section, we demonstrate how to evaluate the previously finetuned model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVMz0DFg_bVN"
      },
      "outputs": [],
      "source": [
        "! pip install transformers comet-llm comet-ml sentencepiece --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "md_zRyNd_Y9W",
        "outputId": "bbaafa05-e272-4ba0-90fa-90b12fa028b8"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "from transformers import AutoModelForCausalLM\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import comet_llm\n",
        "\n",
        "COMET_WORKSPACE = os.getenv(\"COMET_WORKSPACE\")\n",
        "COMET_API_KEY = os.getenv(\"COMET_API_KEY\")\n",
        "\n",
        "transformers.set_seed(35)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqKpzb85_Y9X"
      },
      "source": [
        "### Load the Finetuned Model\n",
        "\n",
        "The first step is to load the finetuned model. You can load the model different ways, but in this example, we download our model and tokenizer from Comet (we stored them there in the last assignment), and then use Huggingface's Transformers library  to load the pretrained model and tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Remote Model 'josephlyu/Emotion-T5-Base:1.0.0' download has been started asynchronously.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 10 file(s), remaining 1.14 GB/1.14 GB\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 1.13 GB/1.14 GB, Throughput 682.22 KB/s, ETA ~1740s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 1.12 GB/1.14 GB, Throughput 814.13 KB/s, ETA ~1443s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 1.11 GB/1.14 GB, Throughput 611.27 KB/s, ETA ~1907s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 1.10 GB/1.14 GB, Throughput 747.32 KB/s, ETA ~1545s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 1.08 GB/1.14 GB, Throughput 1.19 MB/s, ETA ~930s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 1.06 GB/1.14 GB, Throughput 1.33 MB/s, ETA ~822s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 1.04 GB/1.14 GB, Throughput 1.46 MB/s, ETA ~732s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 1.03 GB/1.14 GB, Throughput 882.53 KB/s, ETA ~1223s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 1.02 GB/1.14 GB, Throughput 815.36 KB/s, ETA ~1309s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 1020.03 MB/1.14 GB, Throughput 1.46 MB/s, ETA ~700s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 979.03 MB/1.14 GB, Throughput 2.72 MB/s, ETA ~361s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 945.03 MB/1.14 GB, Throughput 2.25 MB/s, ETA ~420s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 926.03 MB/1.14 GB, Throughput 1.26 MB/s, ETA ~735s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 907.03 MB/1.14 GB, Throughput 1.26 MB/s, ETA ~720s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 878.03 MB/1.14 GB, Throughput 1.92 MB/s, ETA ~457s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 847.03 MB/1.14 GB, Throughput 2.05 MB/s, ETA ~413s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 819.03 MB/1.14 GB, Throughput 1.86 MB/s, ETA ~442s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 792.03 MB/1.14 GB, Throughput 1.79 MB/s, ETA ~443s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 769.03 MB/1.14 GB, Throughput 1.53 MB/s, ETA ~505s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 2 file(s), remaining 733.03 MB/1.14 GB, Throughput 2.39 MB/s, ETA ~308s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 687.47 MB/1.14 GB, Throughput 3.02 MB/s, ETA ~228s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 615.47 MB/1.14 GB, Throughput 4.77 MB/s, ETA ~129s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 493.47 MB/1.14 GB, Throughput 8.10 MB/s, ETA ~61s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 380.47 MB/1.14 GB, Throughput 7.49 MB/s, ETA ~51s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 316.47 MB/1.14 GB, Throughput 4.25 MB/s, ETA ~75s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 287.47 MB/1.14 GB, Throughput 1.92 MB/s, ETA ~150s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 257.47 MB/1.14 GB, Throughput 1.99 MB/s, ETA ~130s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 195.47 MB/1.14 GB, Throughput 4.11 MB/s, ETA ~48s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 123.47 MB/1.14 GB, Throughput 4.77 MB/s, ETA ~26s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 79.47 MB/1.14 GB, Throughput 2.92 MB/s, ETA ~28s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 48.47 MB/1.14 GB, Throughput 2.05 MB/s, ETA ~24s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still downloading 1 file(s), remaining 29.47 MB/1.14 GB, Throughput 1.26 MB/s, ETA ~24s\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Remote Model 'josephlyu/Emotion-T5-Base:1.0.0' has been successfully downloaded.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Downloaded asset files is in './deploy' folder.\n"
          ]
        }
      ],
      "source": [
        "# Download model from registry:\n",
        " \n",
        "from comet_ml import API\n",
        "\n",
        "api = API(api_key=COMET_API_KEY)\n",
        "\n",
        "# model name\n",
        "model_name = \"Emotion-T5-Base\"\n",
        "\n",
        "#get the Model object\n",
        "model = api.get_model(workspace=COMET_WORKSPACE, model_name=model_name)\n",
        "\n",
        "# Download a Registry Model:\n",
        "model.download(\"1.0.0\", \"./deploy\", expand=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HVwiQRJWPfc"
      },
      "source": [
        "The `model.download()` method will download not only the model file, but all the related assets we logged, meaning we can point Huggingface's `from_pretrained()` method directly at our download folder and everything will just work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4jGejoru_Y9Y"
      },
      "outputs": [],
      "source": [
        "# load model and tokenizer\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"./deploy/checkpoint-7\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"./deploy/checkpoint-7/\")\n",
        "\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwFUZU38_Y9Y"
      },
      "source": [
        "### Load the Data to Evaluate\n",
        "\n",
        "The next step is to load the evaluation dataset. We are reloading the dataset from the previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NgKH5AxA_Y9Y"
      },
      "outputs": [],
      "source": [
        "emotion_dataset_val_temp = pd.read_json(path_or_buf=\"https://raw.githubusercontent.com/comet-ml/comet-llmops/main/data/merged_training_sample_prepared_valid.jsonl\", lines=True)\n",
        "emotion_dataset_test = emotion_dataset_val_temp.iloc[int(len(emotion_dataset_val_temp)/2):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KjnMtBDQ_Y9Y",
        "outputId": "8f2ac4ba-5cfe-463c-f4b0-7cfb08bbf6cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i feel very very disturbed right now i dont know how to say this but guess i couldnt sleep tonight just to think about this about him\\n\\n###\\n\\n',\n",
              " 'i feel make them the most dangerous and their level of annoyance is what gives them high priority\\n\\n###\\n\\n',\n",
              " 'i can feel sympathetic joy for my boyfriend and colleagues the latter being like times harder than the former\\n\\n###\\n\\n',\n",
              " 'i found these emails from scott dale and just reading them frusterated me so much that i feel the need to post them and show the world what a neurotic freak he was is\\n\\n###\\n\\n',\n",
              " 'i won t lie and say there isn t a part of me that still feels insulted by it\\n\\n###\\n\\n']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emotion_dataset_test.head().prompt.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IScMHEuZ_Y9Y"
      },
      "source": [
        "### Evaluate Finetuned Emotion Classifier\n",
        "\n",
        "Evaluate different models and prompting techniques and log results when prompting the fine-tuned model. As a take-how exercise feel free to log results with few-shot and one-shot prompting using gpt-3.5-turbo. This way it will be possible to compare the finetuned model with other high-performing models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYprKXo2_Y9Z",
        "outputId": "48e62711-3d3b-4ebc-f609-c70cd8f79ec4"
      },
      "outputs": [],
      "source": [
        "# for comet logging\n",
        "comet_llm.init(project=\"emotion-evaluation\")\n",
        "\n",
        "# prompt prefix\n",
        "prefix = \"Classify the provided piece of text into one of the following emotion labels.\\n\\nEmotion labels: ['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']\\n\\nText:\"\n",
        "\n",
        "# prepare prompts\n",
        "prompts = [{\"prompt\": row.prompt.strip(\"\\n\\n###\\n\\n\") + \"\\n\\n\" + \"Emotion output:\", \"completion\": row.completion.strip(\"\\n\").strip(\" \")} for index, row in emotion_dataset_test.iterrows()]\n",
        "\n",
        "# expected results to log\n",
        "actual_completions = [prompt[\"completion\"] for prompt in prompts]\n",
        "\n",
        "# the results from the fine-tuned model\n",
        "finetuned_completions = []\n",
        "\n",
        "for prompt in prompts:\n",
        "\n",
        "    # finetuned model outputs\n",
        "    input_ids = tokenizer.encode(prefix + prompt[\"prompt\"], return_tensors=\"pt\")\n",
        "    output = model.generate(input_ids, do_sample=True, max_new_tokens=1, temperature=0.1)\n",
        "    output_text = tokenizer.decode(output[0], skip_special_tokens=True).strip(\"<pad>\").strip(\" \")\n",
        "    finetuned_completions.append(output_text)\n",
        "\n",
        "    # log the prompts\n",
        "    comet_llm.log_prompt(\n",
        "        prompt = prefix + prompt[\"prompt\"],\n",
        "        tags = [\"flan-t5-base\", \"fine-tuned\"],\n",
        "        metadata = {\n",
        "            \"model_name\": \"flan-t5-base\",\n",
        "            \"temperature\": 0.1,\n",
        "            \"expected_output\": prompt[\"completion\"],\n",
        "        },\n",
        "        output = output_text\n",
        "    )\n",
        "\n",
        "    # exercise: log zero-shot and few-shot results with GPT-3.5-Turbo and GPT-4 and compare with your fine-tuned model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------\n",
            "prompt: {'prompt': 'i put it down on paper like this i don t feel quite as frantic about the upcoming show\\n\\nEmotion output:', 'completion': 'fear'}\n",
            "------------------------\n",
            "input_ids: tensor([[ 4501,  4921,     8,   937,  1466,    13,  1499,   139,    80,    13,\n",
            "             8,   826, 13868, 11241,     5,   262,  7259, 11241,    10,   784,\n",
            "            31,     9,  9369,    31,     6,     3,    31,    89,  2741,    31,\n",
            "             6,     3,    31,  1927,    63,    31,     6,     3,    31,  5850,\n",
            "            15,    31,     6,     3,    31,     7,     9,    26,   655,    31,\n",
            "             6,     3,    31,  3042,   102,  7854,    31,   908,  5027,    10,\n",
            "            23,   474,    34,   323,    30,  1040,   114,    48,     3,    23,\n",
            "           278,     3,    17,   473,   882,    38,     3,  6296,  1225,    81,\n",
            "             8,     3,  4685,   504,   262,  7259,  3911,    10,     1]])\n",
            "------------------------\n",
            "output: tensor([[    0, 11213]])\n",
            "------------------------\n",
            "output_text: nger\n",
            "------------------------\n"
          ]
        }
      ],
      "source": [
        "# View steps from above cell\n",
        "print(\"------------------------\")\n",
        "print(f\"prompt: {prompt}\")\n",
        "print(\"------------------------\")\n",
        "print(f\"input_ids: {input_ids}\")\n",
        "print(\"------------------------\")\n",
        "print(f\"output: {output}\")\n",
        "print(\"------------------------\")\n",
        "print(f\"output_text: {output_text}\")\n",
        "print(\"------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'anger', 'fear', 'joy', 'love', 'sadness', 'surprise'}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "finetuned_completions = [\"anger\" if i==\"nger\" else i for i in finetuned_completions]\n",
        "set(finetuned_completions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWr6Gu6c_Y9Z"
      },
      "source": [
        "### Finetuned Model - Confusion Matrix\n",
        "\n",
        "Prepare a confusion matrix to better understand the performance of the fine-tuned model on the multi-label classification task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lpO7aIbr_Y9Z",
        "outputId": "ac6144db-dcc4-49ff-d079-ca16962b8e0f"
      },
      "outputs": [],
      "source": [
        "# confusion matrix (logged to experiments as well)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# map completion labels to integers\n",
        "completion_map = {\n",
        "    \"anger\": 0,\n",
        "    \"fear\": 1,\n",
        "    \"joy\": 2,\n",
        "    \"love\": 3,\n",
        "    \"sadness\": 4,\n",
        "    \"surprise\": 5\n",
        "}\n",
        "\n",
        "# mapper back to string labels\n",
        "completion_map_string = {\n",
        "    0: \"anger\",\n",
        "    1: \"fear\",\n",
        "    2: \"joy\",\n",
        "    3: \"love\",\n",
        "    4: \"sadness\",\n",
        "    5: \"surprise\"\n",
        "}\n",
        "\n",
        "actual_completions_int = [completion_map[completion] for completion in actual_completions]\n",
        "finetuned_completions_int = [1 if completion == \"nightmare\" else completion_map[completion] for completion in finetuned_completions]\n",
        "\n",
        "cm = confusion_matrix(actual_completions_int, finetuned_completions_int)\n",
        "\n",
        "# plot confusion matrix\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=0.5, square=True, cmap=\"Blues_r\")\n",
        "\n",
        "# add emotion labels to confusion matrix\n",
        "plt.ylabel(\"Actual label\")\n",
        "plt.xlabel(\"Predicted label\")\n",
        "\n",
        "# annotate the confusion matrix with completion labels\n",
        "tick_marks = [i for i in range(len(completion_map_string))]\n",
        "plt.xticks(tick_marks, list(completion_map_string.values()), rotation=\"vertical\")\n",
        "plt.yticks(tick_marks, list(completion_map_string.values()), rotation=\"horizontal\")\n",
        "plt.savefig(\"imgs/confusion_matrix.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![confusion_matrix](imgs/confusion_matrix.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VPZdrm9_Y9a"
      },
      "source": [
        "### Saving Confusion Matrix\n",
        "\n",
        "The code below saves the confusion matrix to the selected Comet experiment. You can obtained the experiment key from Comet's experiment dashboard.\n",
        "\n",
        "Make sure to change the experiment key to your own experiment key. Refer to the video lecture or [Comet's documentation](https://www.comet.com/docs/v2/api-and-sdk/python-sdk/reference/ExistingExperiment/#existingexperimentlog_code) for how to locate the experiment key for your experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nm2v5lBK_Y9a",
        "outputId": "3663ceae-5628-47b6-de94-6fbb14db136a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch, sklearn.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/josephlyu/emotion-classification/908ff1729dcd4c48bc65d16f4e23ff1a\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'web': 'https://www.comet.com/api/asset/download?assetId=948261be72b54314bf279f2f2dd61a19&experimentKey=908ff1729dcd4c48bc65d16f4e23ff1a',\n",
              " 'api': 'https://www.comet.com/api/rest/v2/experiment/asset/get-asset?assetId=948261be72b54314bf279f2f2dd61a19&experimentKey=908ff1729dcd4c48bc65d16f4e23ff1a',\n",
              " 'assetId': '948261be72b54314bf279f2f2dd61a19'}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "from comet_ml import Experiment\n",
        "\n",
        "experiment = Experiment(api_key=COMET_API_KEY, project_name=\"emotion-classification\")\n",
        "experiment.log_confusion_matrix(actual_completions_int, finetuned_completions_int, labels=list(completion_map_string.values()))\n",
        "experiment.end()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### View in comet dashbaord"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![comet_cm](imgs/comet_cm.png)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llm_twin_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
